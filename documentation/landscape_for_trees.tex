\documentclass[12pt]{article}

\usepackage{amsmath,amssymb,amsthm,mathrsfs,bbm}
\usepackage{latexsym,amscd,amsbsy,dsfont,amsfonts}
\usepackage{graphicx}
\usepackage[pdftex,colorlinks=true]{hyperref}
\usepackage{caption}


% tomas' commands 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\hs}{\hspace{0.15mm}}
\def\TA#1{{\color{red}{[#1]}}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\usepackage{bm}
\usepackage{latexsym}
\usepackage[latin1]{inputenc}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{subfigure}


%\usepackage[hypertexnames=false]{hyperref}
% \usepackage{epsfig}  USAGE: \psfig{file=XXX.eps,width=14cm,angle=0}
%\tighten  \usepackage[hypertexnames=false]{hyperref}

\textwidth = 16.5truecm \textheight = 22truecm
\voffset = -1truecm
\hoffset = -1.5truecm

\begin{document}

\title{A Landscape function for Steiner trees}
\author{Tomas Andrade}

\maketitle

\abstract{We consider a preprocessing heuristic for Steiner trees by means of a {\it landcape function}, which assigns values
to all edges of the graph based on the properties of the terminals. 
%
If a given edge has a value higher than a specified threshold, the edge and associated nodes are discarded from the graph. This reduces the search space of the problem and sometimes leads to clustering, which allows for a divide-and-conquer approach. 
%
For a given (approximate) solver, we compare the performance of the algorithm with an without our preprocessing heuristic
in various case studies in the context of urban network design.
%
We find that the inclusion of our preprocessing strategy in the pipeline produces comparable results 
but significantly reduces computing time. 
}

\tableofcontents

\section{Intro}

Consider a graph $G(V, E)$ with vertices V and edges E, and a proper subset of vertices called {\it terminals}, T. A Steiner tree is a tree graph which goes through all terminals and possibly other nodes in the graph, called {\it Steiner nodes}, minimizing a certain cost function.
For concreteness we can assume that the target function is simply the length of the tree.  \\

[picture] \\

In general this problem is hard -- something about complexity. Simplifications arise in the planar case, where etc etc \\

A common heuristic is -- networkx algoright about metric closure. \\

It is intuitively convenient to combine this or other heuristics with some type of preprocessing of the original graph which allows us to discard edges which will ``obviously'' not be part of the solution. Restrict to graphs embedded in $\mathbb{R}^2$ (possibly with Euclidean 
geometry). This gives rise to the idea of a landscape function $f_T$, which now describe. 

The basic idea is to assign the value $f_T(x_i)$ to the node located at $x_i$, based on the properties of the terminals $T$, 
and to remove the node from the graph if $f_T(x_i) \geq \alpha$, where $\alpha$ is some threshold.  
%
There is of course an enormous freedom in the choice of  $f_T$ and $\alpha$. We will explore some alternatives below and comment on possible extensions. 

An interesting aspect of this procedure is the fact that the removal of certain edges can lead to {\it clustering} i.e. the separation of the original graph into disconnected pieces. 
%
This feature allows us to adopt a divide-and-conquer strategy in the construction of the solution, which once again can be approached in different ways depending on the problem at hand. We will implement a simple algorithm below an comment on plausible alternatives. 


\section{Methodology}

Graph reduction and clustering

\subsection{Landscape function}

We now describe our choice for the landscape function. Consider a graph embedded in $\mathbb{R}^2$, and assign coordinates $x_i$ to the nodes, while the terminals are labelled by $x^{(0)}_j$. Consider a Gaussian centred at terminal $x^{(0)}_j$, with amplitude $A_j$ and width 
$\sigma_j$, 
%
\begin{equation}
	g_j(x) = A_j \exp\left[ \frac{1}{\sigma_j^2}(x -  x^{(0)}_j)^2 \right]
\end{equation}
%
We construct the sum of the gaussians and denote it by 
%
\begin{equation}
	V(x) = \sum_j g_j(x)
\end{equation}
%
This function is of course localized in the location where there is a terminal and decays exponentially away from it. 
We choose the landscape function 
%
\begin{equation}
	f_T(x) = \frac{\epsilon}{\epsilon + V(x)}
\end{equation}
%
Note that $f_T$ goes to $1$ away from the terminals, while it approaches a small value $\sim \epsilon/A_j$ at terminal $j$. 
We depict the landscape function for a small graph in Fig \ref{fig:land1}. 

\begin{figure}[th]
\centering
\includegraphics[width=0.5 \linewidth]{fig/landscape_toy}
\caption{Landscape function for terminals at $(2, 2), (3, 3), (3, 1), (5, 5)$ and $A_0 = 1$, $\sigma_0^2 = 0.5$. We show the constant $0.3$
which shows that the vertices and edges that survive are located inside the ``container''. }
\label{fig:land1}
\end{figure}


\subsection{Threshold}

Our choice for the landscape function naturally yields $\alpha \in (0,1)$. Intuitively, taking  $\alpha = 0$ corresponds
an aggressive reduction heuristic, since it leads to the removal of all edges. On the other hand, the choice $\alpha = 1$ 
does not remove any edges. 
%
Intermediate values remove some edges and keep others, and the details of this process in turn depend on how we choose the 
amplitude $A_j$ and width $\sigma_j$ of the Gaussians. Regardless of this details, it is indeed convenient to have $\alpha$ in 
a finite range for sampling purposes. 
%
For simplicity, we will assume that $\sigma_j = \sigma_0$, and $A_j = A_0$, which we expect to give good results when all terminals
have similar importance (e.g. in a non-capacitated Steiner tree).  

We expect there to be some value of $\alpha$ which is optimal for a given problem, we now describe a some approaches to find
a good approximation. It is important to note that evaluating the landscape and checking which nodes and edges remain in the graph
scales linearly with the size of the problem, so we ignore this step in evaluating the time complexity of the algorithm. 
%
We consider two approaches to estimate the best value of $\alpha$:

\begin{itemize}

\item Sample various $\alpha$'s, estimate time complexity with given formula, and run algorithm with best value(s). 
Pros: captures nuances of particular cases; Cons: estimates ignore constants which can misrepresent best values. 

\item Parameter tuning, Bayesian optimization: \TA{Pato?}

\end{itemize}

[Add figure]

\subsection{Clustering}

As mentioned above, removing certain edges can lead to clustering of the original graph, making it amenable to divide and conquer. 
In this circumstance, we will solve for the partial Steiner trees of each disconnected component, and connect the resulting trees with the following heuristic: i) join the smallest and largest trees by two of their terminals, by brute force computing distances between all pairs; 
ii) move to the next smallest tree. Note that this heuristic scales as $k^2$ where $k$ is the number of terminals. \\

[Add figure]

\subsubsection{Quotient graphs?}

\TA{Pato?}

\subsection{Parallelization}

%It is worth mentioning that when the reduction heuristic results in clustering, we can parallelize parts of the computation. The most promising ones are the following:

The parts of the algorithm which seem amenable to parallelization are the following

\begin{itemize}

\item Solve the problem for the top ranked values of $\alpha$

\item Computation of each partial Steiner tree in case of clustering

\item Compute the distance between all pair of terminals

\end{itemize}


\subsection{Metrics}

We will measure the performance of the algorithms by their computation (wall) time and the total length of the produced trees. \\

\noindent Baseline: networkx's algo without removing edges. 

\section{Case studies}

Compete against Networkx and perhaps an algo from SteinLib

\subsection{Steiner on a grid}

\subsection{Urban with real data}



\end{document}


